{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ab4b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录: e:\\1.code\\Jupyter-notebook\\MUST-DataScience\\1-groupwork\n",
      "原始数据目录: e:\\1.code\\Jupyter-notebook\\MUST-DataScience\\1-groupwork\\dataprocess\\original\n",
      "Bad Samples 数据目录: e:\\1.code\\Jupyter-notebook\\MUST-DataScience\\1-groupwork\\dataprocess\\bad_samples\n",
      "增强后训练集保存目录: e:\\1.code\\Jupyter-notebook\\MUST-DataScience\\1-groupwork\\dataprocess\\augmented\\train\n",
      "增强后测试集保存目录: e:\\1.code\\Jupyter-notebook\\MUST-DataScience\\1-groupwork\\dataprocess\\augmented\\test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageFilter\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import shutil\n",
    "\n",
    "# 设置随机种子\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "workshop_dir = os.path.abspath(\"..\")  \n",
    "original_dir = os.path.join(workshop_dir, \"dataprocess\", \"original\")\n",
    "bad_samples_dir = os.path.join(workshop_dir, \"dataprocess\", \"bad_samples\")\n",
    "\n",
    "# 增强后数据分为 train 和 test 两个目录\n",
    "aug_train_dir = os.path.join(workshop_dir, \"dataprocess\", \"augmented\", \"train\")\n",
    "aug_test_dir = os.path.join(workshop_dir, \"dataprocess\", \"augmented\", \"test\")\n",
    "\n",
    "# 清空并重新创建目录\n",
    "for d in [aug_train_dir, aug_test_dir]:\n",
    "    if os.path.exists(d):\n",
    "        shutil.rmtree(d)\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"当前工作目录:\", workshop_dir)\n",
    "print(\"原始数据目录:\", original_dir)\n",
    "print(\"Bad Samples 数据目录:\", bad_samples_dir)\n",
    "print(\"增强后训练集保存目录:\", aug_train_dir)\n",
    "print(\"增强后测试集保存目录:\", aug_test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8345982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = (224, 224)  # MobileNet / ResNet / EfficientNet 通用尺寸\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    \"\"\"使用 PIL 读取图片，统一尺寸，去噪，颜色校正，归一化\"\"\"\n",
    "    try:\n",
    "        # PIL 读取图片\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = img.resize(TARGET_SIZE, Image.Resampling.BILINEAR)\n",
    "        img = np.array(img)\n",
    "        #  归一化到 [0,1]\n",
    "        img = img / 255.0\n",
    "\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(\"读取失败:\", img_path, e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d083881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_geometric(img):\n",
    "    \"\"\"旋转 ±15° + 翻转 + 随机裁剪\"\"\"\n",
    "    img = Image.fromarray((img*255).astype(np.uint8))\n",
    "    \n",
    "    # 旋转\n",
    "    angle = np.random.uniform(-15, 15)\n",
    "    img = img.rotate(angle,resample=Image.Resampling.BILINEAR)\n",
    "    \n",
    "    # 水平镜像翻转\n",
    "    if np.random.rand() < 0.5:\n",
    "        img = ImageOps.mirror(img)\n",
    "    \n",
    "    \n",
    "    # 随机裁剪\n",
    "    w, h = img.size\n",
    "    scale = np.random.uniform(0.85, 1.0)\n",
    "    crop_w, crop_h = int(w*scale), int(h*scale)\n",
    "    x = np.random.randint(0, w - crop_w + 1)\n",
    "    y = np.random.randint(0, h - crop_h + 1)\n",
    "    img = img.crop((x, y, x+crop_w, y+crop_h))\n",
    "    img = img.resize(TARGET_SIZE,Image.Resampling.BILINEAR)\n",
    "    \n",
    "    return np.array(img)/255.0\n",
    "\n",
    "def augment_image(img):\n",
    "    \"\"\"组合增强 pipeline\"\"\"\n",
    "    img = random_geometric(img)\n",
    "    return img\n",
    "\n",
    "def save_image_cv2(filepath,img_array):\n",
    "    \"\"\"\n",
    "    辅助保存函数：处理 RGB -> BGR 的转换和 uint8 转换\n",
    "    \"\"\"\n",
    "    # 1. 还原到 [0, 255]\n",
    "    img_uint8 = (img_array * 255).astype(np.uint8)\n",
    "    # 2. 颜色空间转换 (RGB -> BGR)，因为 cv2.imwrite 需要 BGR\n",
    "    img_bgr = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2BGR)\n",
    "    # 3. 保存\n",
    "    cv2.imwrite(filepath, img_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c4a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "第1步：统计各类别原始图片数量\n",
      "============================================================\n",
      "共有 8 个类别: ['Cherry', 'Cucumber', 'Pearl_millet(bajra)', 'Tobacco-plant', 'banana', 'cotton', 'maize', 'wheat']\n",
      "\n",
      "各类别原始图片数量：\n",
      "  Cherry: 32 张\n",
      "  Cucumber: 31 张\n",
      "  Pearl_millet(bajra): 39 张\n",
      "  Tobacco-plant: 33 张\n",
      "  banana: 31 张\n",
      "  cotton: 32 张\n",
      "  maize: 31 张\n",
      "  wheat: 31 张\n",
      "\n",
      "============================================================\n",
      "第2步：设置各类别增强次数\n",
      "============================================================\n",
      "\n",
      "各类别增强策略：\n",
      "  Cherry: 32 张原图 × (1 + 30次增强) = 992 张\n",
      "  Cucumber: 31 张原图 × (1 + 30次增强) = 961 张\n",
      "  Pearl_millet(bajra): 39 张原图 × (1 + 25次增强) = 1014 张 ★\n",
      "  Tobacco-plant: 33 张原图 × (1 + 30次增强) = 1023 张\n",
      "  banana: 31 张原图 × (1 + 30次增强) = 961 张\n",
      "  cotton: 32 张原图 × (1 + 30次增强) = 992 张\n",
      "  maize: 31 张原图 × (1 + 30次增强) = 961 张\n",
      "  wheat: 31 张原图 × (1 + 30次增强) = 961 张\n",
      "\n",
      "============================================================\n",
      "第3步：数据增强并划分训练/测试集\n",
      "============================================================\n",
      "\n",
      "处理类别: Cherry\n",
      "  原图: 32 张 → 训练: 23 张, 测试: 9 张\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cherry [TRAIN]: 100%|██████████| 23/23 [00:02<00:00,  8.22it/s]\n",
      "Cherry [TRAIN]: 100%|██████████| 23/23 [00:02<00:00,  8.22it/s]\n",
      "Cherry [TEST]: 100%|██████████| 9/9 [00:01<00:00,  8.34it/s]\n",
      "Cherry [TEST]: 100%|██████████| 9/9 [00:01<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  生成: 训练集 713 张, 测试集 279 张\n",
      "\n",
      "处理类别: Cucumber\n",
      "  原图: 31 张 → 训练: 22 张, 测试: 9 张\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cucumber [TRAIN]: 100%|██████████| 22/22 [00:02<00:00,  7.87it/s]\n",
      "Cucumber [TRAIN]: 100%|██████████| 22/22 [00:02<00:00,  7.87it/s]\n",
      "Cucumber [TEST]: 100%|██████████| 9/9 [00:01<00:00,  7.73it/s]\n",
      "Cucumber [TEST]: 100%|██████████| 9/9 [00:01<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  生成: 训练集 682 张, 测试集 279 张\n",
      "\n",
      "处理类别: Pearl_millet(bajra)\n",
      "  原图: 39 张 → 训练: 28 张, 测试: 11 张\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pearl_millet(bajra) [TRAIN]: 100%|██████████| 28/28 [00:02<00:00,  9.72it/s]\n",
      "Pearl_millet(bajra) [TRAIN]: 100%|██████████| 28/28 [00:02<00:00,  9.72it/s]\n",
      "Pearl_millet(bajra) [TEST]: 100%|██████████| 11/11 [00:01<00:00, 10.16it/s]\n",
      "Pearl_millet(bajra) [TEST]: 100%|██████████| 11/11 [00:01<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  生成: 训练集 728 张, 测试集 286 张\n",
      "\n",
      "处理类别: Tobacco-plant\n",
      "  原图: 33 张 → 训练: 24 张, 测试: 9 张\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tobacco-plant [TRAIN]: 100%|██████████| 24/24 [00:02<00:00,  8.36it/s]\n",
      "Tobacco-plant [TRAIN]: 100%|██████████| 24/24 [00:02<00:00,  8.36it/s]\n",
      "Tobacco-plant [TEST]: 100%|██████████| 9/9 [00:01<00:00,  8.54it/s]\n",
      "Tobacco-plant [TEST]: 100%|██████████| 9/9 [00:01<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  生成: 训练集 744 张, 测试集 279 张\n",
      "\n",
      "处理类别: banana\n",
      "  原图: 31 张 → 训练: 22 张, 测试: 9 张\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "banana [TRAIN]: 100%|██████████| 22/22 [00:02<00:00,  7.89it/s]\n",
      "banana [TRAIN]: 100%|██████████| 22/22 [00:02<00:00,  7.89it/s]\n",
      "banana [TEST]: 100%|██████████| 9/9 [00:01<00:00,  7.83it/s]\n",
      "banana [TEST]: 100%|██████████| 9/9 [00:01<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  生成: 训练集 682 张, 测试集 279 张\n",
      "\n",
      "处理类别: cotton\n",
      "  原图: 32 张 → 训练: 23 张, 测试: 9 张\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cotton [TRAIN]: 100%|██████████| 23/23 [00:02<00:00,  7.81it/s]\n",
      "cotton [TRAIN]: 100%|██████████| 23/23 [00:02<00:00,  7.81it/s]\n",
      "cotton [TEST]: 100%|██████████| 9/9 [00:01<00:00,  8.02it/s]\n",
      "cotton [TEST]: 100%|██████████| 9/9 [00:01<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  生成: 训练集 713 张, 测试集 279 张\n",
      "\n",
      "处理类别: maize\n",
      "  原图: 31 张 → 训练: 22 张, 测试: 9 张\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "maize [TRAIN]: 100%|██████████| 22/22 [00:02<00:00,  8.15it/s]\n",
      "maize [TRAIN]: 100%|██████████| 22/22 [00:02<00:00,  8.15it/s]\n",
      "maize [TEST]: 100%|██████████| 9/9 [00:01<00:00,  8.11it/s]\n",
      "maize [TEST]: 100%|██████████| 9/9 [00:01<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  生成: 训练集 682 张, 测试集 279 张\n",
      "\n",
      "处理类别: wheat\n",
      "  原图: 31 张 → 训练: 22 张, 测试: 9 张\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wheat [TRAIN]: 100%|██████████| 22/22 [00:02<00:00,  7.74it/s]\n",
      "wheat [TRAIN]: 100%|██████████| 22/22 [00:02<00:00,  7.74it/s]\n",
      "wheat [TEST]: 100%|██████████| 9/9 [00:01<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  生成: 训练集 682 张, 测试集 279 张\n",
      "\n",
      "============================================================\n",
      "数据增强完成！最终统计：\n",
      "============================================================\n",
      "训练集总数: 5626 张\n",
      "测试集总数: 2239 张\n",
      "总计: 7865 张\n",
      "\n",
      "各类别最终样本数：\n",
      "  Cherry: 训练 713 + 测试 279 = 992\n",
      "  Cucumber: 训练 651 + 测试 279 = 930\n",
      "  Pearl_millet(bajra): 训练 676 + 测试 260 = 936\n",
      "  Tobacco-plant: 训练 744 + 测试 279 = 1023\n",
      "  banana: 训练 620 + 测试 279 = 899\n",
      "  cotton: 训练 651 + 测试 248 = 899\n",
      "  maize: 训练 558 + 测试 217 = 775\n",
      "  wheat: 训练 682 + 测试 279 = 961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========== 配置参数 ==========\n",
    "DEFAULT_AUG_TIMES = 30  # 默认增强次数\n",
    "TEST_RATIO = 0.30  # 30% 作为测试集\n",
    "\n",
    "# 特殊类别的增强次数设置\n",
    "SPECIAL_AUG_TIMES = {\n",
    "    \"Pearl_millet(bajra)\": 25,  # 该类别有39张，设置25次增强\n",
    "}\n",
    "\n",
    "# ========== 第1步：统计每个类别的原始图片数量 ==========\n",
    "print(\"=\" * 60)\n",
    "print(\"第1步：统计各类别原始图片数量\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 获取所有类别\n",
    "classes = set()\n",
    "for source_dir in [original_dir, bad_samples_dir]:\n",
    "    if os.path.exists(source_dir):\n",
    "        for d in os.listdir(source_dir):\n",
    "            if os.path.isdir(os.path.join(source_dir, d)):\n",
    "                classes.add(d)\n",
    "classes = sorted(list(classes))\n",
    "print(f\"共有 {len(classes)} 个类别: {classes}\")\n",
    "\n",
    "# 统计每个类别的图片\n",
    "class_images = {}  # {类别: [图片路径列表]}\n",
    "\n",
    "for cls in classes:\n",
    "    class_images[cls] = []\n",
    "    \n",
    "    # 从 original 目录收集\n",
    "    orig_cls_dir = os.path.join(original_dir, cls)\n",
    "    if os.path.exists(orig_cls_dir):\n",
    "        for fname in os.listdir(orig_cls_dir):\n",
    "            if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
    "                class_images[cls].append(os.path.join(orig_cls_dir, fname))\n",
    "    \n",
    "    # 从 bad_samples 目录收集\n",
    "    bad_cls_dir = os.path.join(bad_samples_dir, cls)\n",
    "    if os.path.exists(bad_cls_dir):\n",
    "        for fname in os.listdir(bad_cls_dir):\n",
    "            if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
    "                class_images[cls].append(os.path.join(bad_cls_dir, fname))\n",
    "\n",
    "# 打印统计信息\n",
    "print(\"\\n各类别原始图片数量：\")\n",
    "for cls in classes:\n",
    "    print(f\"  {cls}: {len(class_images[cls])} 张\")\n",
    "\n",
    "# ========== 第2步：设置每个类别的增强次数 ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"第2步：设置各类别增强次数\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class_aug_times = {}\n",
    "for cls in classes:\n",
    "    if cls in SPECIAL_AUG_TIMES:\n",
    "        class_aug_times[cls] = SPECIAL_AUG_TIMES[cls]\n",
    "    else:\n",
    "        class_aug_times[cls] = DEFAULT_AUG_TIMES\n",
    "\n",
    "print(\"\\n各类别增强策略：\")\n",
    "for cls in classes:\n",
    "    num_orig = len(class_images[cls])\n",
    "    aug_times = class_aug_times[cls]\n",
    "    total = num_orig * (1 + aug_times) if num_orig > 0 else 0\n",
    "    special_mark = \" ★\" if cls in SPECIAL_AUG_TIMES else \"\"\n",
    "    print(f\"  {cls}: {num_orig} 张原图 × (1 + {aug_times}次增强) = {total} 张{special_mark}\")\n",
    "\n",
    "# ========== 第3步：处理每个类别 ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"第3步：数据增强并划分训练/测试集\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_train = 0\n",
    "total_test = 0\n",
    "\n",
    "for cls in classes:\n",
    "    images = class_images[cls]\n",
    "    aug_times = class_aug_times[cls]\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        print(f\"\\n跳过类别 {cls}：无图片\")\n",
    "        continue\n",
    "    \n",
    "    # 创建输出目录\n",
    "    os.makedirs(os.path.join(aug_train_dir, cls), exist_ok=True)\n",
    "    os.makedirs(os.path.join(aug_test_dir, cls), exist_ok=True)\n",
    "    \n",
    "    # 随机打乱图片顺序\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    # 划分：30% 的原始图片用于生成测试集\n",
    "    test_split = int(len(images) * TEST_RATIO)\n",
    "    test_images = images[:test_split]\n",
    "    train_images = images[test_split:]\n",
    "    \n",
    "    print(f\"\\n处理类别: {cls}\")\n",
    "    print(f\"  原图: {len(images)} 张 → 训练: {len(train_images)} 张, 测试: {len(test_images)} 张\")\n",
    "    \n",
    "    # 处理训练集图片\n",
    "    train_count = 0\n",
    "    for fpath in tqdm(train_images, desc=f\"{cls} [TRAIN]\"):\n",
    "        img = preprocess_image(fpath)\n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        base = os.path.splitext(os.path.basename(fpath))[0]\n",
    "        \n",
    "        # 保存原图\n",
    "        save_image_cv2(os.path.join(aug_train_dir, cls, f\"{base}_base.jpg\"), img)\n",
    "        train_count += 1\n",
    "        \n",
    "        # 数据增强\n",
    "        for i in range(aug_times):\n",
    "            aug_img = augment_image(img)\n",
    "            save_image_cv2(os.path.join(aug_train_dir, cls, f\"{base}_aug{i:02d}.jpg\"), aug_img)\n",
    "            train_count += 1\n",
    "    \n",
    "    # 处理测试集图片\n",
    "    test_count = 0\n",
    "    for fpath in tqdm(test_images, desc=f\"{cls} [TEST]\"):\n",
    "        img = preprocess_image(fpath)\n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        base = os.path.splitext(os.path.basename(fpath))[0]\n",
    "        \n",
    "        # 保存原图\n",
    "        save_image_cv2(os.path.join(aug_test_dir, cls, f\"{base}_base.jpg\"), img)\n",
    "        test_count += 1\n",
    "        \n",
    "        # 数据增强（测试集也做增强以保持一致性）\n",
    "        for i in range(aug_times):\n",
    "            aug_img = augment_image(img)\n",
    "            save_image_cv2(os.path.join(aug_test_dir, cls, f\"{base}_aug{i:02d}.jpg\"), aug_img)\n",
    "            test_count += 1\n",
    "    \n",
    "    total_train += train_count\n",
    "    total_test += test_count\n",
    "    print(f\"  生成: 训练集 {train_count} 张, 测试集 {test_count} 张\")\n",
    "\n",
    "# ========== 最终统计 ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"数据增强完成！最终统计：\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"训练集总数: {total_train} 张\")\n",
    "print(f\"测试集总数: {total_test} 张\")\n",
    "print(f\"总计: {total_train + total_test} 张\")\n",
    "\n",
    "print(\"\\n各类别最终样本数：\")\n",
    "for cls in classes:\n",
    "    train_cls_dir = os.path.join(aug_train_dir, cls)\n",
    "    test_cls_dir = os.path.join(aug_test_dir, cls)\n",
    "    train_n = len(os.listdir(train_cls_dir)) if os.path.exists(train_cls_dir) else 0\n",
    "    test_n = len(os.listdir(test_cls_dir)) if os.path.exists(test_cls_dir) else 0\n",
    "    print(f\"  {cls}: 训练 {train_n} + 测试 {test_n} = {train_n + test_n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
